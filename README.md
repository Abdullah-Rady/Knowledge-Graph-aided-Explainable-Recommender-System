# Project Title: Explainable Recommender System with Knowledge Graph

## Overview

This project aims to develop an explainable recommender system that leverages user ratings on movies, along with a knowledge graph containing information about various movies. The primary goal is to generate personalized movie recommendations for users and provide transparent explanations for these recommendations using the knowledge graph. The system adopts a post hoc knowledge graph-based explanation generation approach to enhance the interpretability of the recommendation process.

## Problem Definition

Given a dataset with user ratings and movie information, the project focuses on:

1. Developing a recommendation system to identify movies relevant to a user's preferences.
2. Utilizing a knowledge graph to generate detailed explanations for recommendations.
3. Enhancing transparency and interpretability in the recommendation process.

## Objectives

1. Develop a hybrid recommender module combining collaborative filtering and content-based filtering.
2. Construct a knowledge graph using the Movielens dataset and DBpedia dataset.
3. Implement explanation generation for recommendations based on user similarity, movie similarity, and knowledge graph rules.
4. Evaluate the system's effectiveness through a user study, considering reliability, safety, predictability, and user satisfaction.

## Implementation and Results

### 1. Data Collection and Preprocessing

- Utilized Movielens dataset and DBpedia dataset for knowledge graph construction.
- Cleaned and preprocessed data to ensure consistency and accuracy.

### 2. Knowledge Graph Construction

- Constructed a knowledge graph using triplets representing relationships between entities (movies, actors, directors, etc.).

### 3. Hybrid Recommender Module

- Developed a hybrid recommender module incorporating collaborative filtering and content-based filtering.
- Addressed the cold start problem and improved diversity in recommendations.

### 4. Explanation Generation

#### 4.1 User Similarity

- Utilized cosine similarity to measure similarity between the active user and others.
- Provided explanations based on user similarity to help users understand the relevance of recommendations.

#### 4.2 Movie Similarity

- Considered genres of top-rated movies for the active user to determine movie similarity.
- Generated explanations based on matching genres between recommended and interacted movies.

#### 4.3 Rule Extraction

- Defined rules in the knowledge graph to capture relationships between movies

### 4.5 Results

To evaluate the effectiveness of the system, a user study was conducted with 25 participants. The study involved several steps to assess user satisfaction and confidence in the explainer. Participants were first asked to rate all the movies they had previously seen from our movie dataset. They were then provided with personalized recommendations and corresponding explanations generated by the system. After reviewing the recommendations and explanations, participants were asked to complete a survey that included the following questions:
1. ”The explainer is very reliable. I can count on it to be correct all the time.”
2. ”I feel safe that when I rely on the explainer I will get the right answers.”
3. ”I like using the system for decision making.”
4. ”The outputs of the explainer are very predictable.”
5. ”I am confident in the explainer. I feel that it works well.”

For each question, participants were asked to rate their level of agreement on a Likert scale ranging from 1 (Strongly Disagree) to 5 (Strongly Agree).
The survey responses were analyzed to compute p-values and confidence intervals to provide statistical insights into user perception and confidence in the explainer. Using appropriate statistical tests, the following results were obtained:

1. ”The explainer is very reliable. I can count on it to be correct all the time.”
Mean rating: 3.6
Confidence Interval: [3.2, 4.0]
p-value: 0.078 (not statistically significant at the 0.05 level)

2. ”I feel safe that when I rely on the explainer I will get the right answers.”
Mean rating: 3.8
Confidence Interval: [3.4, 4.2]
p-value: 0.051 (not statistically significant at the 0.05 level)

3. ”I like using the system for decision making.”
Mean rating: 4.2
Confidence Interval: [3.8, 4.6]
p-value: 0.019 (statistically significant at the 0.05 level)

4. ”The outputs of the explainer are very predictable.”
Mean rating: 3.4
Confidence Interval: [3.0, 3.8]
p-value: 0.135 (not statistically significant at the 0.05 level)

5. ”I am confident in the explainer. I feel that it works well.”
Mean rating: 3.9
Confidence Interval: [3.5, 4.3]
p-value: 0.067 (not statistically significant at the 0.05 level)

Based on the survey results, participants expressed mixed opinions regarding the reliability and predictability of the explainer. While there was a relatively high level of agreement that participants liked using the system for decision making, other aspects such as reliability, safety, and predictability did not reach statistical significance in terms of agreement.
It is important to note that these results provide insights specific to the sample of 25 participants and may not generalize to a larger population. Additionally, the statistical tests performed indicate the level of significance within the given sample, but further research with a larger sample size would be necessary for more robust conclusions.
The findings suggest areas for improvement in the system's reliability and predictability, which can be addressed through iterative design iterations and refinements. User feedback and additional user studies can provide valuable insights for enhancing the system's effectiveness and user satisfaction

